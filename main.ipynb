{
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoboske/wine-quality-deep-learning/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ucimlrepo scikit-learn pandas numpy matplotlib tensorflow >/dev/null 2>&1"
      ],
      "metadata": {
        "id": "vzJADhLEUfJn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# fetch dataset\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "red_wine = wine_quality.data.original.query('color == \"red\"')\n",
        "white_wine = wine_quality.data.original.query('color == \"white\"')\n",
        "\n",
        "columns_to_drop = ['quality', 'color']\n",
        "\n",
        "# print(wine_quality.data.features)\n",
        "num_classes = 11\n",
        "X_red = red_wine.drop(columns=columns_to_drop)\n",
        "y_red = tf.keras.utils.to_categorical(red_wine['quality'], num_classes=num_classes)\n",
        "\n",
        "X_white = white_wine.drop(columns=columns_to_drop)\n",
        "y_white = tf.keras.utils.to_categorical(white_wine['quality'], num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "zpzs1zHNVo1x",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_graph(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def std_deviation_score(X, y=None):\n",
        "    return np.std(X, axis=0)"
      ],
      "metadata": {
        "id": "aDOaEqxUY4lW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import concurrent.futures\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_red_train, X_red_test, y_red_train, y_red_test = train_test_split(X_red, y_red, test_size=0.09, random_state=42)\n",
        "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(X_white, y_white, test_size=0.09, random_state=42)\n",
        "\n",
        "# Create a Pipeline for feature selection and scaling\n",
        "# Define the pipeline steps\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Scaling\n",
        "    ('selector', SelectKBest(score_func=std_deviation_score, k=8)),\n",
        "    ('pca', PCA(n_components=3))\n",
        "])\n",
        "\n",
        "# Fit and transform the pipeline on the training data (for both red and white wine)\n",
        "X_red_train_processed = pipeline.fit_transform(X_red_train, y_red_train)\n",
        "X_white_train_processed = pipeline.fit_transform(X_white_train, y_white_train)\n",
        "\n",
        "# Transform the test data (for both red and white wine)\n",
        "X_red_test_processed = pipeline.transform(X_red_test)\n",
        "X_white_test_processed = pipeline.transform(X_white_test)"
      ],
      "metadata": {
        "id": "rJzTJGn55cfY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Red Wine Model\n",
        "red_wine_model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=X_red_train_processed.shape[1:]),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(16, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(16, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ],\n",
        "     name=\"red-wine\"\n",
        ")\n",
        "\n",
        "# White Wine Model (similar structure, adjust input shape)\n",
        "white_wine_model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=X_white_train_processed.shape[1:]),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(16, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(16, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(16, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(16, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ],\n",
        "    name=\"white-wine\"\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max')\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',  # Metric to monitor (e.g., validation loss)\n",
        "    factor=0.2,          # Factor to reduce learning rate by (e.g., reduce by half)\n",
        "    patience=5,          # Number of epochs with no improvement before reducing\n",
        "    min_lr=0.001      # Minimum learning rate allowed\n",
        ")\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "optimizer_red = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "optimizer_white = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Compile models (choose appropriate optimizer, loss, metrics)\n",
        "red_wine_model.compile(optimizer=optimizer_red, loss=loss_fn, metrics=['accuracy'])\n",
        "white_wine_model.compile(optimizer=optimizer_white, loss=loss_fn, metrics=['accuracy', 'mse'])\n",
        "\n",
        "# Train the models\n",
        "def train_model(model, X_train, y_train, **kwargs):\n",
        "    return model.fit(X_train, y_train, **kwargs)\n",
        "\n",
        "# Train the models concurrently using ThreadPoolExecutor\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Submit the training tasks for both models\n",
        "    red_wine_future = executor.submit(train_model, red_wine_model, X_red_train_processed, y_red_train, batch_size=64, epochs=600, validation_split=0.3, validation_freq=1, callbacks=[callback, lr_scheduler], verbose=1)\n",
        "    white_wine_future = executor.submit(train_model, white_wine_model, X_white_train_processed, y_white_train, batch_size=64, epochs=600, validation_split=0.3, validation_freq=1, callbacks=[callback, lr_scheduler], verbose=1)\n",
        "\n",
        "    # Get the results (history objects)\n",
        "    red_wine_history = red_wine_future.result()\n",
        "    white_wine_history = white_wine_future.result()\n",
        "\n",
        "plot_graph(red_wine_history)\n",
        "plot_graph(white_wine_history)"
      ],
      "metadata": {
        "id": "lalatCMrk_9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4770d225-5827-45e0-c6e9-3611358a0787"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4547 - loss: 1.2872 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3145 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 97/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4591 - loss: 1.2905 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3148 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 98/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4552 - loss: 1.2815 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3139 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 99/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4609 - loss: 1.2758 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3161 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 100/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4417 - loss: 1.3056 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3148 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 101/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4482 - loss: 1.2761 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3168 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 102/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4610 - loss: 1.2681 - mse: 0.0607 - val_accuracy: 0.4522 - val_loss: 1.3160 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 103/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4375 - loss: 1.2940 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3165 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 104/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4466 - loss: 1.2921 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3165 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 105/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4706 - loss: 1.2573 - mse: 0.0604 - val_accuracy: 0.4522 - val_loss: 1.3176 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 106/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4373 - loss: 1.2880 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3172 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 107/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4458 - loss: 1.2904 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3162 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 108/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4689 - loss: 1.2537 - mse: 0.0603 - val_accuracy: 0.4522 - val_loss: 1.3183 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 109/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4567 - loss: 1.2939 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3187 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 110/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4629 - loss: 1.2711 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3178 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 111/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4485 - loss: 1.2890 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3178 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 112/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4482 - loss: 1.2879 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3189 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 113/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4421 - loss: 1.2863 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3182 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 114/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 1.2647 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3188 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 115/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4584 - loss: 1.2709 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3180 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 116/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4497 - loss: 1.2649 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3200 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 117/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4661 - loss: 1.2706 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3183 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 118/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4473 - loss: 1.3015 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3190 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 119/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4504 - loss: 1.2872 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3196 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 120/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4568 - loss: 1.2838 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3187 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 121/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4538 - loss: 1.2692 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3195 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 122/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4518 - loss: 1.2855 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3197 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 123/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4606 - loss: 1.2845 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3205 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 124/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4482 - loss: 1.2948 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3195 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 125/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4492 - loss: 1.2860 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3209 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 126/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4593 - loss: 1.2747 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3200 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 127/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4384 - loss: 1.2923 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3203 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 128/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4559 - loss: 1.2710 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3193 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 129/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4446 - loss: 1.2979 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3224 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 130/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4444 - loss: 1.3188 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3207 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 131/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4580 - loss: 1.2869 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3219 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 132/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4595 - loss: 1.2788 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3222 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 133/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4394 - loss: 1.2928 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3219 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 134/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4502 - loss: 1.2895 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3216 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 135/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4470 - loss: 1.3158 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3234 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 136/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4552 - loss: 1.2926 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3214 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 137/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4448 - loss: 1.2987 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3219 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 138/600\n",
            "\u001b[1m19/98\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4765 - loss: 1.3098 - mse: 0.0612   "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-15fa3607902f>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mred_wine_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mred_wine_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mwhite_wine_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhite_wine_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-15fa3607902f>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Train the models concurrently using ThreadPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Submit the training tasks for both models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mred_wine_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred_wine_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_red_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_red_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m22/98\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4770 - loss: 1.3038 - mse: 0.0611"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model (you can use various metrics like accuracy, precision, recall, etc.)\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Predictions for red and white wine\n",
        "y_red_wine_pred = red_wine_model.predict(X_red_test_processed)  # Predictions for red wine\n",
        "y_white_wine_pred = white_wine_model.predict(X_white_test_processed) # Predictions for white wine\n",
        "\n",
        "# Convert predictions to class labels (if necessary)\n",
        "y_red_wine_pred_classes = np.argmax(y_red_wine_pred, axis=1)\n",
        "y_white_wine_pred_classes = np.argmax(y_white_wine_pred, axis=1)\n",
        "\n",
        "# Convert y_red_test to multiclass format to match y_red_wine_pred_classes\n",
        "y_red_test_classes = np.argmax(y_red_test, axis=1)\n",
        "# Convert y_white_test to multiclass format to match y_white_wine_pred_classes\n",
        "y_white_test_classes = np.argmax(y_white_test, axis=1)\n",
        "\n",
        "\n",
        "# Evaluate Red Wine Model\n",
        "accuracy_red = accuracy_score(y_red_test_classes, y_red_wine_pred_classes)\n",
        "recall_red = recall_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted')\n",
        "precision_red = precision_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted', zero_division=0.0)\n",
        "f1_red = f1_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted')\n",
        "\n",
        "# Evaluate White Wine Model\n",
        "accuracy_white = accuracy_score(y_white_test_classes, y_white_wine_pred_classes)\n",
        "recall_white = recall_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted')\n",
        "precision_white = precision_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted', zero_division=0.0)\n",
        "f1_white = f1_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted')\n",
        "\n",
        "# Create data for DataFrame\n",
        "data = [\n",
        "    [f\"{red_wine_model.name} ({', '.join(map(str, [*red_wine_model.layers[0].input.shape[1:], *[layer.units for layer in red_wine_model.layers if isinstance(layer, tf.keras.layers.Dense)]]))})\", accuracy_red, recall_red, precision_red, f1_red],\n",
        "    [f\"{white_wine_model.name} ({', '.join(map(str, [*white_wine_model.layers[0].input.shape[1:], *[layer.units for layer in white_wine_model.layers if isinstance(layer, tf.keras.layers.Dense)]]))})\", accuracy_white, recall_white, precision_white, f1_white]\n",
        "]\n",
        "\n",
        "headers = [\"Model\", \"Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"]\n",
        "\n",
        "# print(red_wine_model.summary())\n",
        "# print(white_wine_model.summary())\n",
        "\n",
        "print(pd.DataFrame(data, None, headers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLlrU1ZInzHS",
        "outputId": "11f9d38e-c844-4161-d4a5-af26341b5dd6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4399 - loss: 1.2786 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3250 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 143/600\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4533 - loss: 1.2702 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3250 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 144/600\n",
            "                                               Model  Accuracy    Recall  \\\n",
            "0           red-wine (3, 16, 16, 16, 80, 32, 64, 11)  0.430556  0.430556   \n",
            "1  white-wine (3, 16, 16, 16, 16, 64, 64, 64, 64,...  0.433107  0.433107   \n",
            "\n",
            "   Precision  F1 Score  \n",
            "0   0.185378  0.259169  \n",
            "1   0.187581  0.261783  \n"
          ]
        }
      ]
    }
  ],
  "nbformat": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  }
}