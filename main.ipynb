{
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoboske/wine-quality-deep-learning/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ucimlrepo scikit-learn pandas numpy matplotlib tensorflow >/dev/null 2>&1"
      ],
      "metadata": {
        "id": "vzJADhLEUfJn",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# fetch dataset\n",
        "wine_quality = fetch_ucirepo(id=186)\n",
        "red_wine = wine_quality.data.original.query('color == \"red\"')\n",
        "white_wine = wine_quality.data.original.query('color == \"white\"')\n",
        "\n",
        "columns_to_drop = ['quality', 'color']\n",
        "\n",
        "# print(wine_quality.data.features)\n",
        "num_classes = 11\n",
        "X_red = red_wine.drop(columns=columns_to_drop)\n",
        "y_red = tf.keras.utils.to_categorical(red_wine['quality'], num_classes=num_classes)\n",
        "\n",
        "X_white = white_wine.drop(columns=columns_to_drop)\n",
        "y_white = tf.keras.utils.to_categorical(white_wine['quality'], num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "zpzs1zHNVo1x",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_graph(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "aDOaEqxUY4lW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import concurrent.futures\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_red_train, X_red_test, y_red_train, y_red_test = train_test_split(X_red, y_red, test_size=0.09, random_state=42)\n",
        "X_white_train, X_white_test, y_white_train, y_white_test = train_test_split(X_white, y_white, test_size=0.09, random_state=42)\n",
        "\n",
        "# Create a Pipeline for feature selection and scaling\n",
        "# Define the pipeline steps\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Scaling\n",
        "    ('selector', PCA(n_components=8))\n",
        "])\n",
        "\n",
        "# Fit and transform the pipeline on the training data (for both red and white wine)\n",
        "X_red_train_processed = pipeline.fit_transform(X_red_train, y_red_train)\n",
        "X_white_train_processed = pipeline.fit_transform(X_white_train, y_white_train)\n",
        "\n",
        "# Transform the test data (for both red and white wine)\n",
        "X_red_test_processed = pipeline.transform(X_red_test)\n",
        "X_white_test_processed = pipeline.transform(X_white_test)"
      ],
      "metadata": {
        "id": "rJzTJGn55cfY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Red Wine Model\n",
        "red_wine_model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=X_red_train_processed.shape[1:]),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.1),\n",
        "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ],\n",
        "     name=\"red-wine\"\n",
        ")\n",
        "\n",
        "# White Wine Model (similar structure, adjust input shape)\n",
        "white_wine_model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=X_white_train_processed.shape[1:]),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(32, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(80, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ],\n",
        "    name=\"white-wine\"\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',  # Metric to monitor (e.g., validation loss)\n",
        "    factor=0.2,          # Factor to reduce learning rate by (e.g., reduce by half)\n",
        "    patience=5,          # Number of epochs with no improvement before reducing\n",
        "    min_lr=0.001      # Minimum learning rate allowed\n",
        ")\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "optimizer_red = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "optimizer_white = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Compile models (choose appropriate optimizer, loss, metrics)\n",
        "red_wine_model.compile(optimizer=optimizer_red, loss=loss_fn, metrics=['accuracy'])\n",
        "white_wine_model.compile(optimizer=optimizer_white, loss=loss_fn, metrics=['accuracy', 'mse'])\n",
        "\n",
        "# Train the models\n",
        "def train_model(model, X_train, y_train, **kwargs):\n",
        "    return model.fit(X_train, y_train, **kwargs)\n",
        "\n",
        "# Train the models concurrently using ThreadPoolExecutor\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Submit the training tasks for both models\n",
        "    red_wine_future = executor.submit(train_model, red_wine_model, X_red_train_processed, y_red_train_resampled, epochs=600, validation_split=0.3, validation_freq=1, callbacks=[callback, lr_scheduler], verbose=1)\n",
        "    white_wine_future = executor.submit(train_model, white_wine_model, X_white_train_processed, y_white_train_resampled, batch_size=32, epochs=600, validation_split=0.3, validation_freq=1, callbacks=[callback, lr_scheduler], verbose=1)\n",
        "\n",
        "    # Get the results (history objects)\n",
        "    red_wine_history = red_wine_future.result()\n",
        "    white_wine_history = white_wine_future.result()\n",
        "\n",
        "plot_graph(red_wine_history)\n",
        "plot_graph(white_wine_history)"
      ],
      "metadata": {
        "id": "lalatCMrk_9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414b9982-2e14-4161-b004-edcf0891c743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "Epoch 1/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.2136 - loss: 5.5312 - val_accuracy: 0.3959 - val_loss: 4.8652 - learning_rate: 0.0100\n",
            "Epoch 2/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4213 - loss: 4.7858 - val_accuracy: 0.3959 - val_loss: 4.5473 - learning_rate: 0.0100\n",
            "Epoch 3/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4454 - loss: 4.5287 - val_accuracy: 0.3959 - val_loss: 4.4612 - learning_rate: 0.0100\n",
            "Epoch 4/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4355 - loss: 4.4605 - val_accuracy: 0.3982 - val_loss: 4.3954 - learning_rate: 0.0100\n",
            "Epoch 5/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4431 - loss: 4.4362 - val_accuracy: 0.3959 - val_loss: 4.3650 - learning_rate: 0.0100\n",
            "Epoch 6/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4525 - loss: 4.3180 - val_accuracy: 0.3982 - val_loss: 4.3017 - learning_rate: 0.0100\n",
            "Epoch 7/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4337 - loss: 4.3194 - val_accuracy: 0.3959 - val_loss: 4.2652 - learning_rate: 0.0100\n",
            "Epoch 8/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4440 - loss: 4.2597 - val_accuracy: 0.4005 - val_loss: 4.2159 - learning_rate: 0.0100\n",
            "Epoch 9/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4359 - loss: 4.2011 - val_accuracy: 0.3982 - val_loss: 4.1789 - learning_rate: 0.0100\n",
            "Epoch 10/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4318 - loss: 4.1780 - val_accuracy: 0.5515 - val_loss: 4.1287 - learning_rate: 0.0100\n",
            "Epoch 11/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4469 - loss: 4.1658 - val_accuracy: 0.3982 - val_loss: 4.1058 - learning_rate: 0.0100\n",
            "Epoch 12/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4470 - loss: 4.0850 - val_accuracy: 0.5675 - val_loss: 4.0494 - learning_rate: 0.0100\n",
            "Epoch 13/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.3696 - loss: 2.6066 - mse: 0.0668 - val_accuracy: 0.4522 - val_loss: 1.3322 - val_mse: 0.0620 - learning_rate: 0.0100\n",
            "Epoch 2/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4572 - loss: 4.0594 - val_accuracy: 0.4897 - val_loss: 4.0153 - learning_rate: 0.0100\n",
            "Epoch 14/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4892 - loss: 4.0065 - val_accuracy: 0.5217 - val_loss: 3.9847 - learning_rate: 0.0100\n",
            "Epoch 15/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4635 - loss: 1.3128 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3044 - val_mse: 0.0611 - learning_rate: 0.0100\n",
            "Epoch 3/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4788 - loss: 3.9755 - val_accuracy: 0.5675 - val_loss: 3.9327 - learning_rate: 0.0100\n",
            "Epoch 16/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4393 - loss: 3.9675 - val_accuracy: 0.4600 - val_loss: 3.9047 - learning_rate: 0.0100\n",
            "Epoch 17/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4911 - loss: 3.8953 - val_accuracy: 0.6156 - val_loss: 3.8593 - learning_rate: 0.0100\n",
            "Epoch 18/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4375 - loss: 1.3288 - mse: 0.0624 - val_accuracy: 0.4522 - val_loss: 1.3167 - val_mse: 0.0616 - learning_rate: 0.0100\n",
            "Epoch 4/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5035 - loss: 3.8792 - val_accuracy: 0.3982 - val_loss: 3.8523 - learning_rate: 0.0100\n",
            "Epoch 19/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4828 - loss: 3.8601 - val_accuracy: 0.5538 - val_loss: 3.7905 - learning_rate: 0.0100\n",
            "Epoch 20/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4962 - loss: 3.7896 - val_accuracy: 0.5698 - val_loss: 3.7520 - learning_rate: 0.0100\n",
            "Epoch 21/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5107 - loss: 3.7736 - val_accuracy: 0.5240 - val_loss: 3.7241 - learning_rate: 0.0100\n",
            "Epoch 22/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4458 - loss: 1.3176 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3032 - val_mse: 0.0610 - learning_rate: 0.0100\n",
            "Epoch 5/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 3.7094 - val_accuracy: 0.5584 - val_loss: 3.6879 - learning_rate: 0.0020\n",
            "Epoch 23/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 3.7101 - val_accuracy: 0.5606 - val_loss: 3.6816 - learning_rate: 0.0020\n",
            "Epoch 24/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5275 - loss: 3.6915 - val_accuracy: 0.5492 - val_loss: 3.6762 - learning_rate: 0.0020\n",
            "Epoch 25/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5006 - loss: 3.7090 - val_accuracy: 0.5538 - val_loss: 3.6683 - learning_rate: 0.0020\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4482 - loss: 1.2899 - mse: 0.0615Epoch 26/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4482 - loss: 1.2905 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3156 - val_mse: 0.0617 - learning_rate: 0.0020\n",
            "Epoch 6/600\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 3.7453 - val_accuracy: 0.5561 - val_loss: 3.6676 - learning_rate: 0.0010\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4377 - loss: 1.3114 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3122 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 7/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4424 - loss: 1.3150 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3093 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 8/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4492 - loss: 1.2911 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3082 - val_mse: 0.0613 - learning_rate: 0.0010\n",
            "Epoch 9/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4460 - loss: 1.2831 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3142 - val_mse: 0.0616 - learning_rate: 0.0010\n",
            "Epoch 10/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4432 - loss: 1.2975 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3055 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 11/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4454 - loss: 1.3157 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3144 - val_mse: 0.0614 - learning_rate: 0.0010\n",
            "Epoch 12/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4584 - loss: 1.2935 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3096 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 13/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4486 - loss: 1.2885 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3061 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 14/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4433 - loss: 1.3066 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3066 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 15/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4617 - loss: 1.2881 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3050 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 16/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4410 - loss: 1.2827 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3087 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 17/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4420 - loss: 1.3068 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3053 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 18/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4600 - loss: 1.2673 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3062 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 19/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4558 - loss: 1.3108 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3082 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 20/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4660 - loss: 1.2895 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3057 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 21/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4357 - loss: 1.2774 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3042 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 22/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4421 - loss: 1.3031 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3103 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 23/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4570 - loss: 1.2862 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3082 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 24/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4473 - loss: 1.2801 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3115 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 25/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4476 - loss: 1.2778 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3076 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 26/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4486 - loss: 1.2820 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3101 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 27/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4386 - loss: 1.2964 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3066 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 28/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4543 - loss: 1.2835 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3101 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 29/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4515 - loss: 1.2774 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3059 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 30/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4432 - loss: 1.2833 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3113 - val_mse: 0.0614 - learning_rate: 0.0010\n",
            "Epoch 31/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4299 - loss: 1.3262 - mse: 0.0629 - val_accuracy: 0.4522 - val_loss: 1.3068 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 32/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4610 - loss: 1.2797 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3074 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 33/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4229 - loss: 1.3180 - mse: 0.0627 - val_accuracy: 0.4522 - val_loss: 1.3140 - val_mse: 0.0613 - learning_rate: 0.0010\n",
            "Epoch 34/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4545 - loss: 1.3080 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3097 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 35/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4413 - loss: 1.3112 - mse: 0.0623 - val_accuracy: 0.4522 - val_loss: 1.3089 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 36/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4476 - loss: 1.2744 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3037 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 37/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4618 - loss: 1.2960 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3155 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 38/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4539 - loss: 1.2763 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3088 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 39/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4510 - loss: 1.2851 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3076 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 40/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4569 - loss: 1.2919 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3061 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 41/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4555 - loss: 1.2606 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3071 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 42/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4495 - loss: 1.2850 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3107 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 43/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4381 - loss: 1.2880 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3120 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 44/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4457 - loss: 1.2918 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3085 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 45/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4539 - loss: 1.2773 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3061 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 46/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4479 - loss: 1.2757 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3066 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 47/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4354 - loss: 1.2794 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3061 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 48/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4400 - loss: 1.2979 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3098 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 49/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4540 - loss: 1.2794 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3067 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 50/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4503 - loss: 1.2716 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3057 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 51/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4566 - loss: 1.2797 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3083 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 52/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4480 - loss: 1.2984 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3053 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 53/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4384 - loss: 1.2957 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3091 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 54/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4477 - loss: 1.3018 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3066 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 55/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4520 - loss: 1.2894 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3048 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 56/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4479 - loss: 1.2683 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3098 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 57/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4535 - loss: 1.2907 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3071 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 58/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4598 - loss: 1.2910 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3075 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 59/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4538 - loss: 1.2712 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3094 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 60/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4563 - loss: 1.2625 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3043 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 61/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4412 - loss: 1.3133 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3056 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 62/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4327 - loss: 1.2976 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3061 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 63/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4530 - loss: 1.2819 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3064 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 64/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4468 - loss: 1.2776 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3070 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 65/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4561 - loss: 1.2710 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3103 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 66/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4598 - loss: 1.2828 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3080 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 67/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4534 - loss: 1.2755 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3090 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 68/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4397 - loss: 1.3002 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3085 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 69/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4400 - loss: 1.3002 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3081 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 70/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4387 - loss: 1.2944 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3101 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 71/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4549 - loss: 1.2600 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3102 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 72/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4433 - loss: 1.2830 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3107 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 73/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4497 - loss: 1.2688 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3106 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 74/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4496 - loss: 1.2878 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3104 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 75/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4494 - loss: 1.2974 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3104 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 76/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4497 - loss: 1.2826 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3109 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 77/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 1.2743 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3128 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 78/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4652 - loss: 1.2749 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3147 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 79/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4514 - loss: 1.2797 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3127 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 80/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4583 - loss: 1.2915 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3124 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 81/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4524 - loss: 1.3081 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3139 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 82/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4448 - loss: 1.2992 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3125 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 83/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4370 - loss: 1.2961 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3141 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 84/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4490 - loss: 1.2783 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3133 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 85/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4487 - loss: 1.3045 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3145 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 86/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4598 - loss: 1.2729 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3148 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 87/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4616 - loss: 1.2775 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3140 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 88/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4498 - loss: 1.2784 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3154 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 89/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4396 - loss: 1.3002 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3149 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 90/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4364 - loss: 1.2881 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3145 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 91/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4537 - loss: 1.2864 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3156 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 92/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4442 - loss: 1.2765 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3162 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 93/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4574 - loss: 1.2782 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3155 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 94/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4332 - loss: 1.3070 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3160 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 95/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4486 - loss: 1.2859 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3168 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 96/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: 1.3026 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3165 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 97/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4547 - loss: 1.2828 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3155 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 98/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4535 - loss: 1.2732 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3173 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 99/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4442 - loss: 1.2889 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3169 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 100/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4644 - loss: 1.2660 - mse: 0.0607 - val_accuracy: 0.4522 - val_loss: 1.3186 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 101/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4226 - loss: 1.3030 - mse: 0.0624 - val_accuracy: 0.4522 - val_loss: 1.3168 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 102/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4429 - loss: 1.2959 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3173 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 103/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4335 - loss: 1.3008 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3185 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 104/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4629 - loss: 1.2756 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3180 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 105/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4451 - loss: 1.2769 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3208 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 106/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4568 - loss: 1.2822 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3181 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 107/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4415 - loss: 1.2806 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3191 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 108/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4535 - loss: 1.2772 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3198 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 109/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4500 - loss: 1.2753 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3202 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 110/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4445 - loss: 1.2908 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3190 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 111/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4506 - loss: 1.2940 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3200 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 112/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4491 - loss: 1.2772 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3207 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 113/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4572 - loss: 1.2832 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3203 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 114/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4501 - loss: 1.2901 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3197 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 115/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4502 - loss: 1.2976 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3206 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 116/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4460 - loss: 1.2792 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3208 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 117/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4500 - loss: 1.2896 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3199 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 118/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4392 - loss: 1.3180 - mse: 0.0625 - val_accuracy: 0.4522 - val_loss: 1.3197 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 119/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4504 - loss: 1.2787 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3201 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 120/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4586 - loss: 1.2956 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3216 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 121/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4553 - loss: 1.2704 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3217 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 122/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4468 - loss: 1.2937 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3210 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 123/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4474 - loss: 1.2859 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3218 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 124/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4371 - loss: 1.2774 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3219 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 125/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4513 - loss: 1.2866 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3229 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 126/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4742 - loss: 1.2628 - mse: 0.0604 - val_accuracy: 0.4522 - val_loss: 1.3244 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 127/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4465 - loss: 1.2858 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3237 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 128/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4464 - loss: 1.2897 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3230 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 129/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4518 - loss: 1.2841 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3239 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 130/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4546 - loss: 1.2918 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3246 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 131/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4541 - loss: 1.2859 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3248 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 132/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4652 - loss: 1.2746 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3237 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 133/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4426 - loss: 1.2921 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3239 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 134/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4415 - loss: 1.2887 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3241 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 135/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4519 - loss: 1.2839 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3244 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 136/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4515 - loss: 1.2812 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3254 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 137/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4565 - loss: 1.2697 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3253 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 138/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4430 - loss: 1.2802 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3244 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 139/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4542 - loss: 1.2903 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3251 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 140/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4377 - loss: 1.3025 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3243 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 141/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4575 - loss: 1.2871 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3264 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 142/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4457 - loss: 1.3003 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3252 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 143/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4463 - loss: 1.2887 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3247 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 144/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4570 - loss: 1.2869 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3275 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 145/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4673 - loss: 1.2743 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3262 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 146/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4553 - loss: 1.2748 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3250 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 147/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4516 - loss: 1.2934 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3264 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 148/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4621 - loss: 1.2772 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3263 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 149/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4601 - loss: 1.2715 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3259 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 150/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4597 - loss: 1.2947 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3273 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 151/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4539 - loss: 1.2946 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3279 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 152/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4431 - loss: 1.3168 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3273 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 153/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4520 - loss: 1.2920 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3269 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 154/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4425 - loss: 1.2909 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3271 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 155/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4485 - loss: 1.2860 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3268 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 156/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4641 - loss: 1.2744 - mse: 0.0607 - val_accuracy: 0.4522 - val_loss: 1.3286 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 157/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4357 - loss: 1.2989 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3275 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 158/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4648 - loss: 1.2738 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3284 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 159/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4516 - loss: 1.2849 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3291 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 160/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4556 - loss: 1.2627 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3293 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 161/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4474 - loss: 1.3036 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3280 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 162/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4429 - loss: 1.3114 - mse: 0.0619 - val_accuracy: 0.4522 - val_loss: 1.3286 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 163/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4339 - loss: 1.2992 - mse: 0.0620 - val_accuracy: 0.4522 - val_loss: 1.3295 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 164/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4521 - loss: 1.2737 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3292 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 165/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4490 - loss: 1.2924 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3304 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 166/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4636 - loss: 1.2625 - mse: 0.0607 - val_accuracy: 0.4522 - val_loss: 1.3300 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 167/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4385 - loss: 1.2868 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3308 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 168/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4447 - loss: 1.2908 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3292 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 169/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4613 - loss: 1.2839 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3303 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 170/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4482 - loss: 1.3020 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3306 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 171/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4469 - loss: 1.2996 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3310 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 172/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4440 - loss: 1.2941 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3320 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 173/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4639 - loss: 1.2765 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3307 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 174/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4616 - loss: 1.2768 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3319 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 175/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4670 - loss: 1.2681 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3307 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 176/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4596 - loss: 1.2786 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3306 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 177/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4393 - loss: 1.2760 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3326 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 178/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4494 - loss: 1.2840 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3314 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 179/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4386 - loss: 1.3229 - mse: 0.0623 - val_accuracy: 0.4522 - val_loss: 1.3311 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 180/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4531 - loss: 1.2860 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3322 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 181/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4533 - loss: 1.2683 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3321 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 182/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4531 - loss: 1.2797 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3318 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 183/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4562 - loss: 1.2862 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3329 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 184/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4374 - loss: 1.2855 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3329 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 185/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4412 - loss: 1.3015 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3312 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 186/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4422 - loss: 1.2961 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3347 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 187/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4600 - loss: 1.2694 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3336 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 188/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4447 - loss: 1.2788 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3333 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 189/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4492 - loss: 1.2901 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3348 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 190/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4556 - loss: 1.2875 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3328 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 191/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4450 - loss: 1.2930 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3332 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 192/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4441 - loss: 1.3135 - mse: 0.0621 - val_accuracy: 0.4522 - val_loss: 1.3346 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 193/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4524 - loss: 1.2607 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3335 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 194/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4440 - loss: 1.2962 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3343 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 195/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4384 - loss: 1.3082 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3344 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 196/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4355 - loss: 1.2889 - mse: 0.0618 - val_accuracy: 0.4522 - val_loss: 1.3367 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 197/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4442 - loss: 1.2878 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3365 - val_mse: 0.0612 - learning_rate: 0.0010\n",
            "Epoch 198/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4421 - loss: 1.2837 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3364 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 199/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4473 - loss: 1.2840 - mse: 0.0614 - val_accuracy: 0.4522 - val_loss: 1.3358 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 200/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4610 - loss: 1.2698 - mse: 0.0609 - val_accuracy: 0.4522 - val_loss: 1.3358 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 201/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4617 - loss: 1.2758 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3356 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 202/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4554 - loss: 1.2781 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3362 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 203/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4562 - loss: 1.2811 - mse: 0.0612 - val_accuracy: 0.4522 - val_loss: 1.3360 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 204/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4562 - loss: 1.2930 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3354 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 205/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4463 - loss: 1.2914 - mse: 0.0617 - val_accuracy: 0.4522 - val_loss: 1.3364 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 206/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4509 - loss: 1.2922 - mse: 0.0615 - val_accuracy: 0.4522 - val_loss: 1.3372 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 207/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4459 - loss: 1.2884 - mse: 0.0616 - val_accuracy: 0.4522 - val_loss: 1.3368 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 208/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4573 - loss: 1.2790 - mse: 0.0611 - val_accuracy: 0.4522 - val_loss: 1.3372 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 209/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4599 - loss: 1.2900 - mse: 0.0613 - val_accuracy: 0.4522 - val_loss: 1.3363 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 210/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4365 - loss: 1.3088 - mse: 0.0622 - val_accuracy: 0.4522 - val_loss: 1.3364 - val_mse: 0.0610 - learning_rate: 0.0010\n",
            "Epoch 211/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4559 - loss: 1.2662 - mse: 0.0608 - val_accuracy: 0.4522 - val_loss: 1.3376 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 212/600\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4569 - loss: 1.2692 - mse: 0.0610 - val_accuracy: 0.4522 - val_loss: 1.3380 - val_mse: 0.0611 - learning_rate: 0.0010\n",
            "Epoch 213/600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model (you can use various metrics like accuracy, precision, recall, etc.)\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Predictions for red and white wine\n",
        "y_red_wine_pred = red_wine_model.predict(X_red_test_processed)  # Predictions for red wine\n",
        "y_white_wine_pred = white_wine_model.predict(X_white_test_processed) # Predictions for white wine\n",
        "\n",
        "# Convert predictions to class labels (if necessary)\n",
        "y_red_wine_pred_classes = np.argmax(y_red_wine_pred, axis=1)\n",
        "y_white_wine_pred_classes = np.argmax(y_white_wine_pred, axis=1)\n",
        "\n",
        "# Convert y_red_test to multiclass format to match y_red_wine_pred_classes\n",
        "y_red_test_classes = np.argmax(y_red_test, axis=1)\n",
        "# Convert y_white_test to multiclass format to match y_white_wine_pred_classes\n",
        "y_white_test_classes = np.argmax(y_white_test, axis=1)\n",
        "\n",
        "\n",
        "# Evaluate Red Wine Model\n",
        "accuracy_red = accuracy_score(y_red_test_classes, y_red_wine_pred_classes)\n",
        "recall_red = recall_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted')\n",
        "precision_red = precision_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted', zero_division=0.0)\n",
        "f1_red = f1_score(y_red_test_classes, y_red_wine_pred_classes, average='weighted')\n",
        "\n",
        "# Evaluate White Wine Model\n",
        "accuracy_white = accuracy_score(y_white_test_classes, y_white_wine_pred_classes)\n",
        "recall_white = recall_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted')\n",
        "precision_white = precision_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted', zero_division=0.0)\n",
        "f1_white = f1_score(y_white_test_classes, y_white_wine_pred_classes, average='weighted')\n",
        "\n",
        "# Create data for DataFrame\n",
        "data = [\n",
        "    [f\"{red_wine_model.name} ({', '.join(map(str, [*red_wine_model.layers[0].input.shape[1:], *[layer.units for layer in red_wine_model.layers if isinstance(layer, tf.keras.layers.Dense)]]))})\", accuracy_red, recall_red, precision_red, f1_red],\n",
        "    [f\"{white_wine_model.name} ({', '.join(map(str, [*white_wine_model.layers[0].input.shape[1:], *[layer.units for layer in white_wine_model.layers if isinstance(layer, tf.keras.layers.Dense)]]))})\", accuracy_white, recall_white, precision_white, f1_white]\n",
        "]\n",
        "\n",
        "headers = [\"Model\", \"Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"]\n",
        "\n",
        "# print(red_wine_model.summary())\n",
        "# print(white_wine_model.summary())\n",
        "\n",
        "print(pd.DataFrame(data, None, headers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "TLlrU1ZInzHS",
        "outputId": "123d5ed6-ce89-45e6-f15d-d3091754917b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "`axis` must be fewer than the number of dimensions (1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-17e1e6f2e0d6>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Convert y_red_test to multiclass format to match y_red_wine_pred_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0my_red_test_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_red_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# Convert y_white_test to multiclass format to match y_white_wine_pred_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0my_white_test_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_white_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \"\"\"\n\u001b[1;32m   1228\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \"\"\"\n\u001b[1;32m    734\u001b[0m         \u001b[0mdelegate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_minmax_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_argmax_with_skipna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/compat/numpy/function.py\u001b[0m in \u001b[0;36mvalidate_minmax_axis\u001b[0;34m(axis, ndim)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`axis` must be fewer than the number of dimensions ({ndim})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `axis` must be fewer than the number of dimensions (1)"
          ]
        }
      ]
    }
  ],
  "nbformat": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    }
  }
}